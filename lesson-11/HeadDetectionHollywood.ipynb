{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to download the data and unpack the zip file. The dataset is very large, so downloading takes quite some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from xml.etree import ElementTree as et\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    if not os.path.exists('HollywoodHeads.zip'):\n",
    "        print('Downloading dataset, this might take a while')\n",
    "        !wget https://www.di.ens.fr/willow/research/headdetection/release/HollywoodHeads.zip\n",
    "    with zipfile.ZipFile('HollywoodHeads.zip') as file:\n",
    "        print('Unzipping dataset')\n",
    "        file.extractall()\n",
    "    os.rename('HollywoodHeads','data')\n",
    "    !rm HollywoodHeads.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import v2 as tf\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.io import ImageReadMode\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.detection.retinanet import RetinaNet, RetinaNetHead\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "from torchvision.models.detection import backbone_utils\n",
    "\n",
    "class HollywoodHeadDataset(Dataset):\n",
    "    def __init__(self, root, transforms=None, mode='train') -> None:\n",
    "        super().__init__()\n",
    "        assert mode.lower() in ['train', 'test', 'val']\n",
    "        self.transforms = transforms\n",
    "        self.root = root\n",
    "\n",
    "        filename = mode.lower() + '.txt'\n",
    "        filepath = os.path.join(root,'Splits',filename)\n",
    "\n",
    "        with open(filepath,'r') as f:\n",
    "            img_names = f.readlines()\n",
    "        self.imgs = [img.strip('\\n') for img in img_names]\n",
    "\n",
    "        self.imgs_dir = os.path.join(root, 'JPEGImages')\n",
    "        self.annot_dir = os.path.join(root, 'Annotations')\n",
    "        #self.classes = ['background','head']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.imgs[idx]+'.jpeg'\n",
    "        image_path = os.path.join(self.imgs_dir,img_filename)\n",
    "\n",
    "        annot_filename = self.imgs[idx]+'.xml'\n",
    "        annot_file_path = os.path.join(self.annot_dir,annot_filename)\n",
    "\n",
    "        img = torchvision.io.read_image(image_path, ImageReadMode.RGB)        \n",
    "        boxes=[]\n",
    "        tree = et.parse(annot_file_path)\n",
    "        root = tree.getroot()\n",
    "        for object in root.findall('object'):\n",
    "            if object.find('bndbox') is not None:\n",
    "                xmin=float(object.find('bndbox').find('xmin').text)\n",
    "                xmax=float(object.find('bndbox').find('xmax').text)\n",
    "\n",
    "                ymin=float(object.find('bndbox').find('ymin').text)\n",
    "                ymax=float(object.find('bndbox').find('ymax').text)\n",
    "\n",
    "                boxes.append([xmin,ymin, xmax,ymax])\n",
    "\n",
    "        img = tv_tensors.Image(img)\n",
    "        if len(boxes)!=0:\n",
    "            boxes = tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=img.shape[-2:])\n",
    "            #We only have one class\n",
    "            labels = torch.ones(boxes.shape[0], dtype=torch.int64)\n",
    "        # If there are no bounding boxes in the image put in a degenerate box and label it as background\n",
    "        else:\n",
    "            boxes = torch.zeros((0,4),dtype=torch.float32)\n",
    "            boxes = tv_tensors.BoundingBoxes(\n",
    "                boxes, format=\"XYXY\", canvas_size=img.shape[-2:])\n",
    "            labels = torch.zeros(0, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        #target[\"area\"] = area\n",
    "        #target[\"iscrowd\"] = iscrowd\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set = 216719, test set = 1302, validation set = 6719\n"
     ]
    }
   ],
   "source": [
    "transforms = tf.Compose([tf.Resize((255,255)),\n",
    "                        tf.ToImage(),\n",
    "                        tf.ConvertImageDtype()])\n",
    "\n",
    "train_set = HollywoodHeadDataset(root='data', mode='train', transforms=transforms)\n",
    "test_set = HollywoodHeadDataset(root='data', mode='test', transforms=transforms)\n",
    "val_set = HollywoodHeadDataset(root='data', mode='val', transforms=transforms)\n",
    "\n",
    "print(f\"Length of train set = {len(train_set)}, test set = {len(test_set)}, validation set = {len(val_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_train=4\n",
    "bs = 16\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "    for b in batch:\n",
    "        images.append(b[0])\n",
    "        targets.append(b[1])\n",
    "    images = torch.stack(images,dim=0)\n",
    "    return images, targets\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=bs_train, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=bs, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_set, batch_size=bs, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, report_freq, device):\n",
    "    epoch_loss=[]\n",
    "    running_loss = 0.0\n",
    "    starttime = time.time()\n",
    "    for j, (images, targets) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            for target in targets:\n",
    "                 for key in target.keys():\n",
    "                      target[key] = target[key].to(device)\n",
    "            batch_loss_dict = model(images,targets)\n",
    "            batch_loss = sum(loss for loss in batch_loss_dict.values())\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(batch_loss.item())\n",
    "            running_loss+=batch_loss.item()\n",
    "            if j%report_freq==report_freq-1:\n",
    "                print(f\"Batch {j+1} finished, \"\n",
    "                      f\"time = {int((time.time()-starttime)/60)} minutes {round((time.time()-starttime)%60,2)} seconds, \"\n",
    "                      f\"loss: {running_loss/report_freq}\")\n",
    "                starttime = time.time()\n",
    "                running_loss = 0.0\n",
    "    return epoch_loss\n",
    "\n",
    "def train_model(model,train_loader, test_loader, optimizer,no_of_epochs, report_freq, device='cpu'):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    #accuracy = []\n",
    "    for epoch in range(no_of_epochs):\n",
    "        epoch_starttime = time.time()\n",
    "        print(f\"START TRAINING FOR EPOCH {epoch + 1}:\")\n",
    "        model.train(True)\n",
    "        epoch_loss = train_epoch(model, train_loader, optimizer, report_freq, device)\n",
    "        train_loss+=epoch_loss\n",
    "            \n",
    "        running_vloss = 0.0\n",
    "        model.eval()\n",
    "        print(f\"Training for epoch {epoch+1} done, time = \"\n",
    "              f\"{int((time.time()-epoch_starttime)/60)} minutes {round((time.time()-epoch_starttime)%60,2)} seconds\")\n",
    "        with torch.no_grad():\n",
    "             for i, (vimages, vtargets) in enumerate(test_loader):\n",
    "                  vbatch_starttime = time.time()\n",
    "                  vloss_dict = model(vimages, vtargets)\n",
    "                  vloss = sum(loss for loss in vloss_dict.values())\n",
    "                  #correct = (torch.argmax(vpred, dim=1) == vlabels).type(torch.FloatTensor)\n",
    "                  val_loss.append(vloss.item())\n",
    "                  running_vloss+=vloss.item()\n",
    "                  #accuracy.append(correct.mean().item())\n",
    "                  print(f\"Completed validation for batch {i+1}, time = \"\n",
    "                        f\"{int((time.time()-vbatch_starttime)/60)} minutes {round((time.time()-vbatch_starttime)%60,2)}\"\n",
    "                        f\"seconds\")\n",
    "        \n",
    "\n",
    "        val_loss.append(running_vloss/(i+1))\n",
    "        train_loss+=epoch_loss\n",
    "        print(f\"Validation for epoch {epoch+1} done, time = \"\n",
    "              f\"{int((time.time()-epoch_starttime)/60)} minutes {round((time.time()-epoch_starttime)%60,2)} seconds, \"\n",
    "              f\"LOSS train {epoch_loss[-1]}, val: {val_loss[-1]}\")\n",
    "\n",
    "        \n",
    "    return train_loss, val_loss#, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RetinaNet(\n",
      "  (backbone): BackboneWithFPN(\n",
      "    (body): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fpn): FeaturePyramidNetwork(\n",
      "      (inner_blocks): ModuleList(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (layer_blocks): ModuleList(\n",
      "        (0-2): 3 x Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (extra_blocks): LastLevelP6P7(\n",
      "        (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (anchor_generator): AnchorGenerator()\n",
      "  (head): RetinaNetHead(\n",
      "    (classification_head): RetinaNetClassificationHead(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cls_logits): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (regression_head): RetinaNetRegressionHead(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (bbox_reg): Conv2d(256, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (transform): GeneralizedRCNNTransform(\n",
      "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "anchor_sizes = tuple((x, int(x * 2 ** (1.0 / 3)), int(x * 2 ** (2.0 / 3))) for x in [8, 16, 32, 64, 128])\n",
    "aspect_ratios = ((0.25, 0.5, 1.0, 1.5),)*len(anchor_sizes)\n",
    "anchor_generator = AnchorGenerator(anchor_sizes,aspect_ratios)\n",
    "\n",
    "trainable_backbone_layers=3\n",
    "backbone = torchvision.models.resnet50(weights='DEFAULT')\n",
    "backbone = backbone_utils._resnet_fpn_extractor(backbone, \n",
    "                                                trainable_layers=trainable_backbone_layers,\n",
    "                                                returned_layers=[2,3,4],\n",
    "                                                extra_blocks=torchvision.ops.feature_pyramid_network.LastLevelP6P7(2048,256))\n",
    "\n",
    "backbone.out_channels=256\n",
    "head = RetinaNetHead(backbone.out_channels,\n",
    "                     anchor_generator.num_anchors_per_location()[0],\n",
    "                     num_classes=2,\n",
    "                     norm_layer=partial(nn.GroupNorm, 32))\n",
    "\n",
    "head.regression_head._loss_type = \"giou\"\n",
    "model = RetinaNet(backbone=backbone, \n",
    "                  num_classes=2, \n",
    "                  anchor_generator=anchor_generator,\n",
    "                  head=head)\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "START TRAINING FOR EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 finished, time = 1 minutes 30.05 seconds, loss: 2.278454065322876\n",
      "Batch 2 finished, time = 1 minutes 23.8 seconds, loss: 2.0172133445739746\n",
      "Batch 3 finished, time = 1 minutes 18.35 seconds, loss: 1.9694371223449707\n",
      "Batch 4 finished, time = 1 minutes 25.26 seconds, loss: 1.774393081665039\n",
      "Batch 5 finished, time = 1 minutes 11.61 seconds, loss: 1.92490553855896\n",
      "Batch 6 finished, time = 1 minutes 2.53 seconds, loss: 1.9260871410369873\n",
      "Batch 7 finished, time = 1 minutes 4.72 seconds, loss: 2.033876419067383\n",
      "Batch 8 finished, time = 1 minutes 14.74 seconds, loss: 2.0134963989257812\n",
      "Batch 9 finished, time = 1 minutes 3.14 seconds, loss: 1.9089078903198242\n",
      "Batch 10 finished, time = 1 minutes 10.88 seconds, loss: 2.082597255706787\n",
      "Batch 11 finished, time = 0 minutes 56.64 seconds, loss: 1.788629174232483\n",
      "Batch 12 finished, time = 0 minutes 59.52 seconds, loss: 1.4914157390594482\n",
      "Batch 13 finished, time = 1 minutes 12.34 seconds, loss: 2.024981737136841\n",
      "Batch 14 finished, time = 1 minutes 5.28 seconds, loss: 1.8251453638076782\n",
      "Batch 15 finished, time = 1 minutes 0.4 seconds, loss: 2.052615165710449\n",
      "Batch 16 finished, time = 1 minutes 8.83 seconds, loss: 1.8033864498138428\n",
      "Batch 17 finished, time = 1 minutes 23.5 seconds, loss: 1.9040400981903076\n",
      "Batch 18 finished, time = 1 minutes 8.94 seconds, loss: 1.6213420629501343\n",
      "Batch 19 finished, time = 0 minutes 58.19 seconds, loss: 1.4858577251434326\n",
      "Batch 20 finished, time = 0 minutes 51.4 seconds, loss: 1.6927404403686523\n",
      "Batch 21 finished, time = 1 minutes 5.61 seconds, loss: 1.823589563369751\n",
      "Batch 22 finished, time = 0 minutes 55.26 seconds, loss: 1.8745837211608887\n",
      "Batch 23 finished, time = 0 minutes 47.69 seconds, loss: 1.7282803058624268\n",
      "Batch 24 finished, time = 1 minutes 0.0 seconds, loss: 1.7436022758483887\n",
      "Batch 25 finished, time = 0 minutes 47.08 seconds, loss: 1.5711910724639893\n",
      "Batch 26 finished, time = 0 minutes 48.29 seconds, loss: 1.8558645248413086\n",
      "Batch 27 finished, time = 0 minutes 46.79 seconds, loss: 1.8215850591659546\n",
      "Batch 28 finished, time = 0 minutes 48.32 seconds, loss: 1.6210215091705322\n",
      "Batch 29 finished, time = 0 minutes 49.66 seconds, loss: 1.7256734371185303\n",
      "Batch 30 finished, time = 0 minutes 48.16 seconds, loss: 1.575336217880249\n",
      "Batch 31 finished, time = 0 minutes 52.11 seconds, loss: 1.8216625452041626\n",
      "Batch 32 finished, time = 1 minutes 2.3 seconds, loss: 1.688166856765747\n",
      "Batch 33 finished, time = 0 minutes 49.57 seconds, loss: 1.771864414215088\n",
      "Batch 34 finished, time = 1 minutes 2.51 seconds, loss: 1.7123572826385498\n",
      "Batch 35 finished, time = 1 minutes 2.9 seconds, loss: 1.8290021419525146\n",
      "Batch 36 finished, time = 1 minutes 3.65 seconds, loss: 1.6646065711975098\n",
      "Batch 37 finished, time = 0 minutes 57.55 seconds, loss: 1.6609535217285156\n",
      "Batch 38 finished, time = 1 minutes 12.88 seconds, loss: 1.6514087915420532\n",
      "Batch 39 finished, time = 1 minutes 38.07 seconds, loss: 1.5611748695373535\n",
      "Batch 40 finished, time = 1 minutes 29.36 seconds, loss: 1.6320619583129883\n",
      "Batch 41 finished, time = 1 minutes 54.47 seconds, loss: 1.586073875427246\n",
      "Batch 42 finished, time = 1 minutes 28.81 seconds, loss: 1.6454308032989502\n",
      "Batch 43 finished, time = 1 minutes 21.31 seconds, loss: 1.6233973503112793\n",
      "Batch 44 finished, time = 1 minutes 12.77 seconds, loss: 1.6303424835205078\n",
      "Batch 45 finished, time = 1 minutes 22.6 seconds, loss: 1.70926833152771\n",
      "Batch 46 finished, time = 1 minutes 9.22 seconds, loss: 1.5958106517791748\n",
      "Batch 47 finished, time = 1 minutes 20.63 seconds, loss: 1.8001387119293213\n",
      "Batch 48 finished, time = 1 minutes 22.68 seconds, loss: 1.6837718486785889\n",
      "Batch 49 finished, time = 1 minutes 17.64 seconds, loss: 1.7071094512939453\n",
      "Batch 50 finished, time = 1 minutes 3.99 seconds, loss: 1.8037687540054321\n",
      "Batch 51 finished, time = 2 minutes 9.9 seconds, loss: 1.6096773147583008\n",
      "Batch 52 finished, time = 2 minutes 11.67 seconds, loss: 1.8082396984100342\n",
      "Batch 53 finished, time = 1 minutes 40.29 seconds, loss: 1.6875295639038086\n",
      "Batch 54 finished, time = 1 minutes 42.49 seconds, loss: 1.827094316482544\n",
      "Batch 55 finished, time = 1 minutes 45.46 seconds, loss: 1.4883050918579102\n",
      "Batch 56 finished, time = 1 minutes 37.56 seconds, loss: 1.5318739414215088\n",
      "Batch 57 finished, time = 1 minutes 37.08 seconds, loss: 1.5341744422912598\n",
      "Batch 58 finished, time = 1 minutes 37.63 seconds, loss: 1.448082685470581\n",
      "Batch 59 finished, time = 1 minutes 50.79 seconds, loss: 1.8604223728179932\n",
      "Batch 60 finished, time = 1 minutes 41.27 seconds, loss: 1.6262116432189941\n",
      "Batch 61 finished, time = 1 minutes 34.78 seconds, loss: 1.639894962310791\n",
      "Batch 62 finished, time = 1 minutes 27.56 seconds, loss: 1.6152472496032715\n",
      "Batch 63 finished, time = 1 minutes 36.34 seconds, loss: 1.5712716579437256\n",
      "Batch 64 finished, time = 1 minutes 24.81 seconds, loss: 1.5682179927825928\n",
      "Batch 65 finished, time = 1 minutes 35.6 seconds, loss: 1.508758306503296\n",
      "Batch 66 finished, time = 1 minutes 45.7 seconds, loss: 1.795477271080017\n",
      "Batch 67 finished, time = 1 minutes 30.91 seconds, loss: 1.7269747257232666\n",
      "Batch 68 finished, time = 1 minutes 48.61 seconds, loss: 1.3789246082305908\n",
      "Batch 69 finished, time = 1 minutes 28.41 seconds, loss: 1.5682731866836548\n",
      "Batch 70 finished, time = 1 minutes 34.48 seconds, loss: 1.8207533359527588\n",
      "Batch 71 finished, time = 1 minutes 18.51 seconds, loss: 1.6898152828216553\n",
      "Batch 72 finished, time = 1 minutes 39.89 seconds, loss: 1.716429352760315\n",
      "Batch 73 finished, time = 1 minutes 24.4 seconds, loss: 1.7682862281799316\n",
      "Batch 74 finished, time = 1 minutes 21.57 seconds, loss: 1.5000462532043457\n",
      "Batch 75 finished, time = 1 minutes 38.9 seconds, loss: 1.8499155044555664\n",
      "Batch 76 finished, time = 1 minutes 23.67 seconds, loss: 1.5005249977111816\n",
      "Batch 77 finished, time = 1 minutes 13.45 seconds, loss: 1.7819030284881592\n",
      "Batch 78 finished, time = 1 minutes 28.52 seconds, loss: 1.6372201442718506\n",
      "Batch 79 finished, time = 1 minutes 27.05 seconds, loss: 1.4015552997589111\n",
      "Batch 80 finished, time = 1 minutes 24.54 seconds, loss: 1.54262113571167\n",
      "Batch 81 finished, time = 1 minutes 22.47 seconds, loss: 1.4731621742248535\n",
      "Batch 82 finished, time = 1 minutes 46.27 seconds, loss: 1.6163644790649414\n",
      "Batch 83 finished, time = 1 minutes 46.73 seconds, loss: 1.416832685470581\n",
      "Batch 84 finished, time = 2 minutes 11.87 seconds, loss: 1.5018835067749023\n",
      "Batch 85 finished, time = 1 minutes 51.46 seconds, loss: 1.6004871129989624\n",
      "Batch 86 finished, time = 1 minutes 35.13 seconds, loss: 1.8228678703308105\n",
      "Batch 87 finished, time = 1 minutes 48.71 seconds, loss: 1.5753955841064453\n",
      "Batch 88 finished, time = 1 minutes 36.99 seconds, loss: 1.7893534898757935\n",
      "Batch 89 finished, time = 1 minutes 10.2 seconds, loss: 1.9811532497406006\n",
      "Batch 90 finished, time = 1 minutes 5.13 seconds, loss: 1.7370131015777588\n",
      "Batch 91 finished, time = 1 minutes 29.64 seconds, loss: 1.6829502582550049\n",
      "Batch 92 finished, time = 1 minutes 14.75 seconds, loss: 1.616551160812378\n",
      "Batch 93 finished, time = 1 minutes 44.6 seconds, loss: 1.3681836128234863\n",
      "Batch 94 finished, time = 0 minutes 59.43 seconds, loss: 1.2061058282852173\n",
      "Batch 95 finished, time = 1 minutes 18.31 seconds, loss: 1.5840144157409668\n",
      "Batch 96 finished, time = 1 minutes 25.42 seconds, loss: 1.1721434593200684\n",
      "Batch 97 finished, time = 1 minutes 25.7 seconds, loss: 1.609790563583374\n",
      "Batch 98 finished, time = 1 minutes 19.3 seconds, loss: 1.5156564712524414\n",
      "Batch 99 finished, time = 1 minutes 15.11 seconds, loss: 1.4845435619354248\n",
      "Batch 100 finished, time = 1 minutes 12.57 seconds, loss: 1.5493972301483154\n",
      "Batch 101 finished, time = 1 minutes 10.62 seconds, loss: 1.4188616275787354\n",
      "Batch 102 finished, time = 1 minutes 24.95 seconds, loss: 1.3070014715194702\n",
      "Batch 103 finished, time = 1 minutes 26.75 seconds, loss: 1.541623830795288\n",
      "Batch 104 finished, time = 1 minutes 7.52 seconds, loss: 1.4644677639007568\n",
      "Batch 105 finished, time = 1 minutes 13.78 seconds, loss: 1.7687656879425049\n",
      "Batch 106 finished, time = 1 minutes 9.85 seconds, loss: 1.5126023292541504\n",
      "Batch 107 finished, time = 1 minutes 14.86 seconds, loss: 1.5634658336639404\n",
      "Batch 108 finished, time = 1 minutes 2.26 seconds, loss: 1.5189306735992432\n",
      "Batch 109 finished, time = 1 minutes 14.53 seconds, loss: 1.5280836820602417\n",
      "Batch 110 finished, time = 1 minutes 7.45 seconds, loss: 1.6196255683898926\n",
      "Batch 111 finished, time = 1 minutes 8.73 seconds, loss: 1.5434787273406982\n",
      "Batch 112 finished, time = 1 minutes 1.07 seconds, loss: 1.5678744316101074\n",
      "Batch 113 finished, time = 1 minutes 23.49 seconds, loss: 1.4396910667419434\n",
      "Batch 114 finished, time = 1 minutes 21.0 seconds, loss: 1.763051986694336\n",
      "Batch 115 finished, time = 1 minutes 0.8 seconds, loss: 1.473065972328186\n",
      "Batch 116 finished, time = 1 minutes 4.66 seconds, loss: 1.4006444215774536\n",
      "Batch 117 finished, time = 1 minutes 14.95 seconds, loss: 1.7413156032562256\n",
      "Batch 118 finished, time = 1 minutes 12.82 seconds, loss: 1.390128493309021\n",
      "Batch 119 finished, time = 1 minutes 14.57 seconds, loss: 1.409583330154419\n",
      "Batch 120 finished, time = 1 minutes 22.79 seconds, loss: 1.5022754669189453\n",
      "Batch 121 finished, time = 1 minutes 11.97 seconds, loss: 1.4545297622680664\n",
      "Batch 122 finished, time = 1 minutes 13.18 seconds, loss: 1.5281853675842285\n",
      "Batch 123 finished, time = 1 minutes 25.22 seconds, loss: 1.4949548244476318\n",
      "Batch 124 finished, time = 1 minutes 10.48 seconds, loss: 1.5007848739624023\n",
      "Batch 125 finished, time = 1 minutes 31.08 seconds, loss: 1.1619802713394165\n",
      "Batch 126 finished, time = 1 minutes 30.73 seconds, loss: 1.2677570581436157\n",
      "Batch 127 finished, time = 1 minutes 48.37 seconds, loss: 1.318282127380371\n",
      "Batch 128 finished, time = 1 minutes 46.61 seconds, loss: 1.6214237213134766\n",
      "Batch 129 finished, time = 1 minutes 15.23 seconds, loss: 1.6484047174453735\n",
      "Batch 130 finished, time = 1 minutes 11.19 seconds, loss: 1.2299636602401733\n",
      "Batch 131 finished, time = 1 minutes 24.64 seconds, loss: 1.2604990005493164\n",
      "Batch 132 finished, time = 1 minutes 10.57 seconds, loss: 1.6309044361114502\n",
      "Batch 133 finished, time = 1 minutes 14.13 seconds, loss: 1.2274696826934814\n",
      "Batch 134 finished, time = 1 minutes 17.12 seconds, loss: 1.4508492946624756\n",
      "Batch 135 finished, time = 1 minutes 14.4 seconds, loss: 1.642504334449768\n",
      "Batch 136 finished, time = 1 minutes 12.95 seconds, loss: 1.401440143585205\n",
      "Batch 137 finished, time = 1 minutes 7.47 seconds, loss: 1.111295461654663\n",
      "Batch 138 finished, time = 1 minutes 25.83 seconds, loss: 1.5692425966262817\n",
      "Batch 139 finished, time = 3 minutes 58.77 seconds, loss: 1.2981770038604736\n",
      "Batch 140 finished, time = 1 minutes 21.13 seconds, loss: 1.2169345617294312\n",
      "Batch 141 finished, time = 2 minutes 5.2 seconds, loss: 1.1275303363800049\n",
      "Batch 142 finished, time = 1 minutes 36.1 seconds, loss: 1.302871584892273\n",
      "Batch 143 finished, time = 1 minutes 21.62 seconds, loss: 1.3855726718902588\n",
      "Batch 144 finished, time = 1 minutes 10.08 seconds, loss: 1.1856911182403564\n",
      "Batch 145 finished, time = 1 minutes 14.72 seconds, loss: 1.351147174835205\n",
      "Batch 146 finished, time = 1 minutes 13.79 seconds, loss: 1.1400026082992554\n",
      "Batch 147 finished, time = 1 minutes 18.6 seconds, loss: 1.3310284614562988\n",
      "Batch 148 finished, time = 1 minutes 7.03 seconds, loss: 1.1815710067749023\n",
      "Batch 149 finished, time = 0 minutes 58.94 seconds, loss: 1.2218718528747559\n",
      "Batch 150 finished, time = 0 minutes 57.41 seconds, loss: 1.3684608936309814\n",
      "Batch 151 finished, time = 1 minutes 13.79 seconds, loss: 1.1624804735183716\n",
      "Batch 152 finished, time = 1 minutes 0.52 seconds, loss: 1.352558970451355\n",
      "Batch 153 finished, time = 1 minutes 0.88 seconds, loss: 1.5230119228363037\n",
      "Batch 154 finished, time = 1 minutes 17.6 seconds, loss: 1.5790011882781982\n",
      "Batch 155 finished, time = 1 minutes 2.48 seconds, loss: 1.198756217956543\n",
      "Batch 156 finished, time = 1 minutes 7.26 seconds, loss: 1.2922554016113281\n",
      "Batch 157 finished, time = 1 minutes 12.9 seconds, loss: 1.3392810821533203\n",
      "Batch 158 finished, time = 1 minutes 12.33 seconds, loss: 1.3371632099151611\n",
      "Batch 159 finished, time = 1 minutes 10.01 seconds, loss: 1.417542815208435\n",
      "Batch 160 finished, time = 1 minutes 12.3 seconds, loss: 1.380804181098938\n",
      "Batch 161 finished, time = 0 minutes 57.55 seconds, loss: 1.6060516834259033\n",
      "Batch 162 finished, time = 1 minutes 6.9 seconds, loss: 1.527498722076416\n",
      "Batch 163 finished, time = 0 minutes 58.81 seconds, loss: 1.3029481172561646\n",
      "Batch 164 finished, time = 0 minutes 59.3 seconds, loss: 1.364079236984253\n",
      "Batch 165 finished, time = 1 minutes 7.99 seconds, loss: 1.25213623046875\n",
      "Batch 166 finished, time = 0 minutes 53.86 seconds, loss: 1.2328267097473145\n",
      "Batch 167 finished, time = 0 minutes 54.83 seconds, loss: 1.3109642267227173\n",
      "Batch 168 finished, time = 0 minutes 48.03 seconds, loss: 1.2617994546890259\n",
      "Batch 169 finished, time = 0 minutes 47.83 seconds, loss: 1.4514811038970947\n",
      "Batch 170 finished, time = 1 minutes 1.56 seconds, loss: 1.324751377105713\n",
      "Batch 171 finished, time = 0 minutes 59.23 seconds, loss: 1.319505214691162\n",
      "Batch 172 finished, time = 0 minutes 56.17 seconds, loss: 1.245781660079956\n",
      "Batch 173 finished, time = 0 minutes 56.39 seconds, loss: 1.1315348148345947\n",
      "Batch 174 finished, time = 0 minutes 47.8 seconds, loss: 1.5884807109832764\n",
      "Batch 175 finished, time = 0 minutes 48.33 seconds, loss: 1.2199991941452026\n",
      "Batch 176 finished, time = 0 minutes 53.7 seconds, loss: 1.1368355751037598\n",
      "Batch 177 finished, time = 1 minutes 12.52 seconds, loss: 1.088407039642334\n",
      "Batch 178 finished, time = 0 minutes 55.07 seconds, loss: 0.9825516939163208\n",
      "Batch 179 finished, time = 0 minutes 47.88 seconds, loss: 1.1411316394805908\n",
      "Batch 180 finished, time = 0 minutes 52.1 seconds, loss: 1.1386258602142334\n",
      "Batch 181 finished, time = 0 minutes 48.06 seconds, loss: 1.074459433555603\n",
      "Batch 182 finished, time = 0 minutes 49.63 seconds, loss: 1.2381304502487183\n",
      "Batch 183 finished, time = 0 minutes 50.87 seconds, loss: 1.0689513683319092\n",
      "Batch 184 finished, time = 0 minutes 47.34 seconds, loss: 1.1222281455993652\n",
      "Batch 185 finished, time = 0 minutes 48.43 seconds, loss: 1.3818655014038086\n",
      "Batch 186 finished, time = 0 minutes 51.11 seconds, loss: 1.152411699295044\n",
      "Batch 187 finished, time = 0 minutes 49.97 seconds, loss: 1.1045596599578857\n",
      "Batch 188 finished, time = 1 minutes 31.0 seconds, loss: 1.2545280456542969\n",
      "Batch 189 finished, time = 1 minutes 14.89 seconds, loss: 0.8020021915435791\n",
      "Batch 190 finished, time = 1 minutes 22.76 seconds, loss: 0.8976106643676758\n",
      "Batch 191 finished, time = 1 minutes 16.85 seconds, loss: 1.2523835897445679\n",
      "Batch 192 finished, time = 1 minutes 25.47 seconds, loss: 1.474839210510254\n",
      "Batch 193 finished, time = 1 minutes 14.21 seconds, loss: 1.313336730003357\n",
      "Batch 194 finished, time = 1 minutes 25.53 seconds, loss: 0.8885966539382935\n",
      "Batch 195 finished, time = 1 minutes 30.75 seconds, loss: 1.259739875793457\n",
      "Batch 196 finished, time = 1 minutes 45.51 seconds, loss: 1.2332971096038818\n",
      "Batch 197 finished, time = 1 minutes 22.06 seconds, loss: 1.4196155071258545\n",
      "Batch 198 finished, time = 1 minutes 10.55 seconds, loss: 1.3052256107330322\n",
      "Batch 199 finished, time = 1 minutes 16.33 seconds, loss: 1.2050327062606812\n",
      "Batch 200 finished, time = 1 minutes 26.9 seconds, loss: 1.2634743452072144\n",
      "Batch 201 finished, time = 1 minutes 19.31 seconds, loss: 1.1113908290863037\n",
      "Batch 202 finished, time = 1 minutes 9.06 seconds, loss: 1.1091334819793701\n",
      "Batch 203 finished, time = 1 minutes 26.92 seconds, loss: 1.0360419750213623\n",
      "Batch 204 finished, time = 1 minutes 25.73 seconds, loss: 1.1727259159088135\n",
      "Batch 205 finished, time = 1 minutes 36.7 seconds, loss: 0.8814369440078735\n",
      "Batch 206 finished, time = 1 minutes 59.17 seconds, loss: 1.1779921054840088\n",
      "Batch 207 finished, time = 2 minutes 1.6 seconds, loss: 1.1879613399505615\n",
      "Batch 208 finished, time = 1 minutes 48.92 seconds, loss: 1.0975782871246338\n",
      "Batch 209 finished, time = 1 minutes 19.87 seconds, loss: 1.3325531482696533\n",
      "Batch 210 finished, time = 1 minutes 29.21 seconds, loss: 1.2494091987609863\n",
      "Batch 211 finished, time = 1 minutes 22.27 seconds, loss: 0.9705488681793213\n",
      "Batch 212 finished, time = 1 minutes 33.55 seconds, loss: 1.0023036003112793\n",
      "Batch 213 finished, time = 2 minutes 46.81 seconds, loss: 1.2753607034683228\n",
      "Batch 214 finished, time = 1 minutes 22.58 seconds, loss: 1.1112746000289917\n"
     ]
    }
   ],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "print(len(params))\n",
    "optimizer = optim.SGD(params,lr=0.001,momentum=0.9)\n",
    "\n",
    "no_of_epochs = 3\n",
    "train_loss, test_loss = train_model(model, train_loader,val_loader, optimizer=optimizer, no_of_epochs=no_of_epochs, report_freq=500, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def draw_pred_bounding_boxes(img, model, img_name):\n",
    "    model.eval()\n",
    "\n",
    "    #img = tv_tensors.Image(img)\n",
    "    pred = model(img)\n",
    "    boxes = pred[\"boxes\"]\n",
    "\n",
    "    img = torchvision.utils.draw_bounding_boxes(img, boxes)\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    fn = img_name+'_pred.jpg'\n",
    "    fp = os.path.join('data/output', fn)\n",
    "    if not os.path.exists('data/output'):\n",
    "        os.mkdir('data/output')\n",
    "    img.save(fp)\n",
    "\n",
    "def draw_annot_bounding_boxes(img_name):\n",
    "    img_dir = 'data/JPEGImages/'\n",
    "    annot_dir = 'data/Annotations/'\n",
    "\n",
    "    annot_filepath = os.path.join(annot_dir, img_name+'.xml')\n",
    "    img_filepath = os.path.join(img_dir, img_name+'.jpeg')\n",
    "    img = torchvision.io.read_image(img_filepath, ImageReadMode.RGB)\n",
    "\n",
    "    img = tv_tensors.Image(img)\n",
    "    boxes=[]\n",
    "    tree = et.parse(annot_filepath)\n",
    "    root = tree.getroot()\n",
    "    for object in root.findall('object'):\n",
    "        if object.find('bndbox') is not None:\n",
    "            xmin=float(object.find('bndbox').find('xmin').text)\n",
    "            xmax=float(object.find('bndbox').find('xmax').text)\n",
    "\n",
    "            ymin=float(object.find('bndbox').find('ymin').text)\n",
    "            ymax=float(object.find('bndbox').find('ymax').text)\n",
    "\n",
    "            boxes.append([xmin,ymin, xmax,ymax])\n",
    "    if len(boxes)!=0:\n",
    "        img = torchvision.utils.draw_bounding_boxes(img, boxes)\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    output_fp = os.path.join('data/output/',img_name+'_annot.jpeg')\n",
    "    img.save(output_fp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
