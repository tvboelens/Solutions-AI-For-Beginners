{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body Segmentation\n",
    "\n",
    "Lab Assignment from [AI for Beginners Curriculum](https://github.com/microsoft/ai-for-beginners).\n",
    "\n",
    "In video production, for example, in weather forecasts, we often need to cut out a human image from camera and place it on top of some other footage. This is typically done using **chroma key** techniques, when a human is filmed in front of a uniform color background, which is then removed. In this lab, we will train a neural network model to cut out the human silhouette.\n",
    "\n",
    "We will be using [Segmentation Full Body MADS Dataset](https://www.kaggle.com/datasets/tapakah68/segmentation-full-body-mads-dataset) from Kaggle. Download the dataset manually from Kaggle and unzip in into current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'segmentation_full_body_mads_dataset_1192_img'\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import shutil\n",
    "from typing import Optional, Callable\n",
    "\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    with zipfile.ZipFile('mads_ds_1192.zip') as file:\n",
    "        file.extractall()\n",
    "    for dir in os.listdir(os.path.join(dataset_path,dataset_path)):\n",
    "        shutil.move(os.path.join(dataset_path, dataset_path, dir),\n",
    "                    os.path.join(dataset_path, dir))\n",
    "    shutil.rmtree(os.path.join(dataset_path, dataset_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how images in the dataset look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(dataset_path,'images')\n",
    "mask_path = os.path.join(dataset_path,'masks')\n",
    "\n",
    "fnames = os.listdir(img_path)\n",
    "\n",
    "def load_image(img_name:str)->tuple:\n",
    "    img = plt.imread(os.path.join(img_path,img_name))\n",
    "    mask = plt.imread(os.path.join(mask_path,img_name))\n",
    "    return img,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask = load_image(fnames[5])\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(mask)\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.io import ImageReadMode\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def draw_pred_segmentation_masks(model: Callable, img: torch.Tensor, img_name: str)->None:\n",
    "    model.eval()\n",
    "    pred = model(img)\n",
    "    img = img.reshape(img.size()[1:]).to(torch.uint8)\n",
    "\n",
    "    pred = pred.reshape(pred.size()[2:]).bool()\n",
    "\n",
    "    img = torchvision.utils.draw_segmentation_masks(img, pred)\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    fn = img_name+'_pred.png'\n",
    "    fp = os.path.join('output_imgs', fn)\n",
    "    if not os.path.exists('output_imgs'):\n",
    "        os.mkdir('output_imgs')\n",
    "    img.save(fp)\n",
    "    img.close()\n",
    "    return None\n",
    "\n",
    "\n",
    "class MADSDataset(Dataset):\n",
    "    def __init__(self, root: str, transforms: Optional[Callable]=None) -> None:\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.imgs_dir = os.path.join(root,'images')\n",
    "        self.masks_dir = os.path.join(root,'masks')\n",
    "        self.img_names = [img_name[:-4] for img_name in os.listdir(self.imgs_dir) \n",
    "                          if os.path.isfile(os.path.join(self.imgs_dir,img_name))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx]\n",
    "        img_fn = img_name+'.png'\n",
    "        img_path = os.path.join(self.imgs_dir,img_fn)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = T.functional.pil_to_tensor(img)\n",
    "        #img = torchvision.io.read_image(img_path, ImageReadMode.RGB)\n",
    "\n",
    "        mask_path = os.path.join(self.masks_dir, self.img_names[idx]+'.png')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        mask = T.functional.pil_to_tensor(mask)\n",
    "        #mask = torchvision.io.read_image(mask_path, ImageReadMode.GRAY)\n",
    "        target = tv_tensors.Mask(mask)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        return img, self.get_class_index(target), img_name\n",
    "\n",
    "    def get_class_index(self, mask):\n",
    "        mask = torch.where(mask>128,torch.ones(mask.size(), dtype=torch.float32),torch.zeros(mask.size(),dtype=torch.float32))\n",
    "        mask = tv_tensors.Mask(mask)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "train_size = 0.7\n",
    "val_size = 0.2\n",
    "test_size = 1.0-(train_size+val_size)\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "transforms = T.Compose([T.Resize((256,256), interpolation=Image.NEAREST),\n",
    "                        T.ToImage(),\n",
    "                        T.ToDtype(dtype={tv_tensors.Image: torch.float32, tv_tensors.Mask: torch.float32, \"others\": None},\n",
    "                                  scale=True)])\n",
    "bs = 16\n",
    "no_of_epochs = 30\n",
    "\n",
    "full_dataset = MADSDataset(root=dataset_path,transforms=transforms)\n",
    "train_set, val_set, test_set = random_split(full_dataset,[train_size,val_size,test_size])\n",
    "train_loader = DataLoader(train_set, batch_size=bs, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=bs, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from statistics import mean\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, loss_fn, report_freq, device):\n",
    "    epoch_loss=[]\n",
    "    running_loss = 0.0\n",
    "    starttime = time.time()\n",
    "    for j, (images, targets, _) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            pred = model(images)\n",
    "            batch_loss = loss_fn(pred, targets)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(batch_loss.item())\n",
    "            running_loss+=batch_loss.item()\n",
    "            if j%report_freq==report_freq-1:\n",
    "                print(f\"Batch {j+1} finished, \"\n",
    "                      f\"time = {int((time.time()-starttime)/60)} minutes {round((time.time()-starttime)%60,2)} seconds, \"\n",
    "                      f\"loss: {running_loss/report_freq}\")\n",
    "                starttime = time.time()\n",
    "                running_loss = 0.0\n",
    "    return epoch_loss\n",
    "\n",
    "def train_model(model,train_loader, val_loader, optimizer,no_of_epochs, report_freq, \n",
    "                device='cpu', loss_fn = nn.BCEWithLogitsLoss()):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for epoch in range(no_of_epochs):\n",
    "        epoch_starttime = time.time()\n",
    "        print(f\"START TRAINING FOR EPOCH {epoch + 1}:\")\n",
    "        model.train(True)\n",
    "        epoch_loss = train_epoch(model, train_loader, optimizer, loss_fn, report_freq, device)\n",
    "        train_loss+=epoch_loss\n",
    "            \n",
    "        running_vloss = 0.0\n",
    "        model.eval()\n",
    "        print(f\"Training for epoch {epoch+1} done, time = \"\n",
    "              f\"{int((time.time()-epoch_starttime)/60)} minutes {round((time.time()-epoch_starttime)%60,2)} seconds\")\n",
    "        with torch.no_grad():\n",
    "            vbatch_starttime = time.time()\n",
    "\n",
    "            for i, (vimages, vtargets, _) in enumerate(val_loader):\n",
    "                  vimages = vimages.to(device)\n",
    "                  vtargets = vtargets.to(device)\n",
    "                  pred = model(vimages)\n",
    "                  vloss = loss_fn(pred, vtargets)\n",
    "                  val_loss.append(vloss.item())\n",
    "                  running_vloss+=vloss.item()\n",
    "                  #print(f\"Completed validation for batch {i+1}, time = \"\n",
    "                  #      f\"{int((time.time()-vbatch_starttime)/60)} minutes {round((time.time()-vbatch_starttime)%60,2)}\"\n",
    "                  #      f\"seconds\")\n",
    "        \n",
    "\n",
    "        val_loss.append(running_vloss/(i+1))\n",
    "        train_loss+=epoch_loss\n",
    "        print(f\"Validation for epoch {epoch+1} done, time = \"\n",
    "              f\"{int((time.time()-epoch_starttime)/60)} minutes {round((time.time()-epoch_starttime)%60,2)} seconds, \"\n",
    "              f\"LOSS train {epoch_loss[-1]}, val: {val_loss[-1]}\")\n",
    "\n",
    "        \n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, save_freq=100, device='cpu', loss_fn = nn.BCEWithLogitsLoss()):\n",
    "      test_loss = []\n",
    "      pixel_acc = []\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "            for i, (img, mask, fn) in enumerate(test_loader):\n",
    "                  img = img.to(device)\n",
    "                  mask = mask.to(device)\n",
    "\n",
    "                  pred = model(img)\n",
    "                  tloss = loss_fn(pred, mask)\n",
    "                  test_loss.append(tloss.item())\n",
    "\n",
    "                  pred = torch.where(pred >=0.5, torch.ones(\n",
    "                      pred.size(), dtype=torch.float32), torch.zeros(pred.size(), dtype=torch.float32))\n",
    "                  correct = (pred==mask).type(dtype=torch.float32)\n",
    "                  pixel_acc.append(torch.sum(correct/torch.numel(correct)).item())\n",
    "                  if (i+1)%save_freq == 0:\n",
    "                        draw_pred_segmentation_masks(model, img, fn[0])\n",
    "      return mean(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc_conv0 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1)\n",
    "        self.act0 = nn.ReLU()\n",
    "        self.bn0 = nn.BatchNorm2d(16)\n",
    "        self.pool0 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.enc_conv1 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.enc_conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.enc_conv3 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.bottleneck_conv = nn.Conv2d(\n",
    "            in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1)\n",
    "\n",
    "        self.upsample0 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.dec_conv0 = nn.Conv2d(\n",
    "            in_channels=384, out_channels=128, kernel_size=(3, 3), padding=1)\n",
    "        self.dec_act0 = nn.ReLU()\n",
    "        self.dec_bn0 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.dec_conv1 = nn.Conv2d(\n",
    "            in_channels=192, out_channels=64, kernel_size=(3, 3), padding=1)\n",
    "        self.dec_act1 = nn.ReLU()\n",
    "        self.dec_bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.dec_conv2 = nn.Conv2d(\n",
    "            in_channels=96, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "        self.dec_act2 = nn.ReLU()\n",
    "        self.dec_bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.upsample3 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.dec_conv3 = nn.Conv2d(\n",
    "            in_channels=48, out_channels=1, kernel_size=(1, 1))\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        e0 = self.pool0(self.bn0(self.act0(self.enc_conv0(x))))\n",
    "        e1 = self.pool1(self.bn1(self.act1(self.enc_conv1(e0))))\n",
    "        e2 = self.pool2(self.bn2(self.act2(self.enc_conv2(e1))))\n",
    "        e3 = self.pool3(self.bn3(self.act3(self.enc_conv3(e2))))\n",
    "\n",
    "        cat0 = self.bn0(self.act0(self.enc_conv0(x)))\n",
    "        cat1 = self.bn1(self.act1(self.enc_conv1(e0)))\n",
    "        cat2 = self.bn2(self.act2(self.enc_conv2(e1)))\n",
    "        cat3 = self.bn3(self.act3(self.enc_conv3(e2)))\n",
    "\n",
    "        b = self.bottleneck_conv(e3)\n",
    "\n",
    "        d0 = self.dec_bn0(self.dec_act0(self.dec_conv0(\n",
    "            torch.cat((self.upsample0(b), cat3), dim=1))))\n",
    "        d1 = self.dec_bn1(self.dec_act1(self.dec_conv1(\n",
    "            torch.cat((self.upsample1(d0), cat2), dim=1))))\n",
    "        d2 = self.dec_bn2(self.dec_act2(self.dec_conv2(\n",
    "            torch.cat((self.upsample2(d1), cat1), dim=1))))\n",
    "        d3 = self.sigmoid(self.dec_conv3(\n",
    "            torch.cat((self.upsample3(d2), cat0), dim=1)))\n",
    "        return d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = UNet()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)#TODO: Define learning rate and weight decay\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_loss, val_loss = train_model(model=model, train_loader=train_loader, val_loader=val_loader,\n",
    "                                   optimizer=optimizer, no_of_epochs=no_of_epochs, report_freq=20, device=device,\n",
    "                                   loss_fn=loss_fn)\n",
    "print(\"TRAINING FINISHED\")\n",
    "test_loss = test_model(model=model, test_loader=test_loader, device=device, loss_fn=loss_fn, save_freq=1)\n",
    "print(f\"Test loss = {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "ax1.plot(train_loss)\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Train Loss\")\n",
    "\n",
    "ax2.plot(val_loss)\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_title(\"Validation Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import Image, display\n",
    "\n",
    "output_path = 'data/output'\n",
    "output_img_names = os.listdir(output_path)\n",
    "output_imgs = [os.path.join(output_path, img_name)\n",
    "               for img_name in output_img_names]\n",
    "for i in range(10):\n",
    "    img = random.choice(output_imgs)\n",
    "    display(Image(filename=img))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16af2a8bbb083ea23e5e41c7f5787656b2ce26968575d8763f2c4b17f9cd711f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
